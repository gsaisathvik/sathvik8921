# -*- coding: utf-8 -*-
"""churnprevention model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_GqWl9mU3XINWlr-IB8RTBZEpGLIKoFe
"""

# Install necessary libraries
!pip install pandas scikit-learn joblib

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import random

def generate_customer_data(num_customers=1000):
    np.random.seed(42)
    random.seed(42)

    data = {
        "customer_id": range(1, num_customers + 1),
        "age": np.random.randint(18, 70, num_customers),
        "gender": np.random.choice(["Male", "Female"], num_customers),
        "region": np.random.choice(["North", "South", "East", "West"], num_customers),
        "policy_type": np.random.choice(["Auto", "Home", "Life", "Health"], num_customers),
        "annual_premium": np.random.randint(500, 5000, num_customers),
        "claims_last_year": np.random.randint(0, 5, num_customers),
        "satisfaction_score": np.random.randint(1, 5, num_customers),
        "contract_length": np.random.randint(12, 60, num_customers),
    }

    df = pd.DataFrame(data)

    # Generate realistic customer_since dates
    end_date = datetime(2024, 12, 31)
    start_date = datetime(2019, 1, 1)
    time_diff = (end_date - start_date).days
    df["customer_since"] = [end_date - timedelta(days=random.randint(0, time_diff)) for _ in range(num_customers)]
    df["customer_since"] = df["customer_since"].dt.strftime("%Y-%m-%d")

    # Introduce some churn based on satisfaction, claims, and contract length
    df["churn"] = 0 # Default to no churn
    df.loc[(df["satisfaction_score"] < 3) & (df["claims_last_year"] > 2), "churn"] = 1
    df.loc[(df["contract_length"] < 24) & (df["annual_premium"] < 1000), "churn"] = 1
    df.loc[np.random.rand(num_customers) < 0.05, "churn"] = 1 # Random churn

    df.to_csv("customer_data.csv", index=False)
    print("Generated customer_data.csv with {} customers.".format(num_customers))
    return df

customer_df = generate_customer_data()
print(customer_df.head())

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import LabelEncoder
import joblib
import os

def train_churn_model(data_path='customer_data.csv', model_path='churn_model.joblib'):
    df = pd.read_csv(data_path)

    # Preprocessing
    for column in ['gender', 'region', 'policy_type']:
        le = LabelEncoder()
        df[column] = le.fit_transform(df[column])

    df['customer_since'] = pd.to_datetime(df['customer_since'])
    df['years_as_customer'] = (pd.to_datetime('2025-01-01') - df['customer_since']).dt.days / 365.25

    columns_to_drop = ['customer_since']
    if 'customer_id' in df.columns:
        columns_to_drop.append('customer_id')
    df = df.drop(columns=columns_to_drop)

    if 'churn' in df.columns:
        X = df.drop('churn', axis=1)
        y = df['churn']
    else:
        raise ValueError("'churn' column not found in the dataset.")

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)
    print("Model Accuracy:", accuracy_score(y_test, y_pred))
    print("\nClassification Report:\n", classification_report(y_test, y_pred))

    joblib.dump(model, model_path)
    print(f"Model saved to {model_path}")

train_churn_model()

import pandas as pd
import joblib
from sklearn.preprocessing import LabelEncoder
import os

def segment_customers(data_path='customer_data.csv', model_path='churn_model.joblib'):
    df = pd.read_csv(data_path)
    model = joblib.load(model_path)

    df_processed = df.copy()
    for column in ['gender', 'region', 'policy_type']:
        le = LabelEncoder()
        df_processed[column] = le.fit_transform(df_processed[column])

    df_processed['customer_since'] = pd.to_datetime(df_processed['customer_since'])
    df_processed['years_as_customer'] = (pd.to_datetime('2025-01-01') - df_processed['customer_since']).dt.days / 365.25

    columns_to_drop_for_prediction = ['customer_since']
    if 'customer_id' in df_processed.columns:
        columns_to_drop_for_prediction.append('customer_id')
    if 'churn' in df_processed.columns:
        columns_to_drop_for_prediction.append('churn')

    # Ensure all columns from training are present, except the ones to be dropped
    # This handles cases where the input data might have extra columns
    # We get the training columns from the model object
    training_columns = model.feature_names_in_
    X_predict = df_processed[training_columns]

    df['churn_probability'] = model.predict_proba(X_predict)[:, 1]

    def assign_churn_risk(prob):
        if prob >= 0.7:
            return 'High Risk'
        elif prob >= 0.4:
            return 'Medium Risk'
        else:
            return 'Low Risk'

    df['churn_risk_segment'] = df['churn_probability'].apply(assign_churn_risk)
    df['customer_segment'] = df['churn_risk_segment'] + ' - ' + df['policy_type']

    return df

segmented_df = segment_customers()
segmented_df.to_csv('segmented_customers.csv', index=False)
print('Generated segmented_customers.csv with customer segments.')
print(segmented_df.head())

import pandas as pd

def get_retention_strategy(customer_segment):
    strategies = {
        # High Risk Segments
        "High Risk - Auto": "Offer premium discount on auto insurance, personalized follow-up call.",
        "High Risk - Home": "Provide home security system upgrade, loyalty bonus.",
        "High Risk - Life": "Review policy benefits, offer financial planning consultation.",
        "High Risk - Health": "Introduce wellness programs, telemedicine access.",

        # Medium Risk Segments
        "Medium Risk - Auto": "Send targeted email campaign with new auto features, offer multi-policy discount.",
        "Medium Risk - Home": "Suggest home maintenance tips, offer smart home device integration.",
        "Medium Risk - Life": "Provide educational content on life insurance benefits, offer policy review.",
        "Medium Risk - Health": "Share health tips, offer preventive care reminders.",

        # Low Risk Segments (general engagement)
        "Low Risk - Auto": "Newsletter with safe driving tips, annual policy review.",
        "Low Risk - Home": "Seasonal home care guides, community engagement events.",
        "Low Risk - Life": "Financial literacy webinars, client appreciation events.",
        "Low Risk - Health": "Health and fitness challenges, healthy recipe sharing."
    }
    return strategies.get(customer_segment, "General engagement communication.")

def apply_retention_strategies(segmented_data_path='segmented_customers.csv'):
    df = pd.read_csv(segmented_data_path)
    df["recommended_strategy"] = df["customer_segment"].apply(get_retention_strategy)
    return df

df_with_strategies = apply_retention_strategies()
df_with_strategies.to_csv('customers_with_strategies.csv', index=False)
print('Generated customers_with_strategies.csv with recommended retention strategies.')
print(df_with_strategies.head())

import pandas as pd
import joblib
from sklearn.preprocessing import LabelEncoder
from datetime import datetime

# Load the trained model
model = joblib.load('churn_model.joblib')

# Re-define get_retention_strategy in case this cell is run independently
def get_retention_strategy(customer_segment):
    strategies = {
        "High Risk - Auto": "Offer premium discount on auto insurance, personalized follow-up call.",
        "High Risk - Home": "Provide home security system upgrade, loyalty bonus.",
        "High Risk - Life": "Review policy benefits, offer financial planning consultation.",
        "High Risk - Health": "Introduce wellness programs, telemedicine access.",
        "Medium Risk - Auto": "Send targeted email campaign with new auto features, offer multi-policy discount.",
        "Medium Risk - Home": "Suggest home maintenance tips, offer smart home device integration.",
        "Medium Risk - Life": "Provide educational content on life insurance benefits, offer policy review.",
        "Medium Risk - Health": "Share health tips, offer preventive care reminders.",
        "Low Risk - Auto": "Newsletter with safe driving tips, annual policy review.",
        "Low Risk - Home": "Seasonal home care guides, community engagement events.",
        "Low Risk - Life": "Financial literacy webinars, client appreciation events.",
        "Low Risk - Health": "Health and fitness challenges, healthy recipe sharing."
    }
    return strategies.get(customer_segment, "General engagement communication.")

def predict_and_recommend(customer_data):
    df = pd.DataFrame([customer_data])

    # Preprocessing
    # Create a copy to avoid SettingWithCopyWarning
    df_processed = df.copy()

    # Label Encoding for categorical features
    # In a real system, you would save and load these encoders to ensure consistency
    for column in ['gender', 'region', 'policy_type']:
        le = LabelEncoder()
        df_processed[column] = le.fit_transform(df_processed[column])

    df_processed['customer_since'] = pd.to_datetime(df_processed['customer_since'])
    df_processed['years_as_customer'] = (pd.to_datetime('2025-01-01') - df_processed['customer_since']).dt.days / 365.25

    # Ensure columns are in the same order as during model training
    training_columns = model.feature_names_in_
    df_processed = df_processed.drop(columns=['customer_since'])
    X_predict = df_processed[training_columns]

    # Predict churn probability
    churn_probability = model.predict_proba(X_predict)[:, 1][0]

    # Determine risk segment
    if churn_probability >= 0.7:
        risk_segment = 'High Risk'
    elif churn_probability >= 0.4:
        risk_segment = 'Medium Risk'
    else:
        risk_segment = 'Low Risk'

    # Get retention strategy
    customer_segment = f"{risk_segment} - {customer_data['policy_type']}"
    recommended_strategy = get_retention_strategy(customer_segment)

    return {
        'churn_probability': float(churn_probability),
        'risk_segment': risk_segment,
        'customer_segment': customer_segment,
        'recommended_strategy': recommended_strategy
    }

# Example usage:
new_customer = {
    'age': 35,
    'gender': "Male",
    'region': "North",
    'policy_type': "Auto",
    'annual_premium': 2500,
    'claims_last_year': 1,
    'satisfaction_score': 4,
    'contract_length': 24,
    'customer_since': "2020-01-15"
}

prediction_results = predict_and_recommend(new_customer)
print("\nPrediction Results for New Customer:")
for key, value in prediction_results.items():
    print(f"- {key.replace('_', ' ').title()}: {value}")

# Example usage:
new_customer = {
    'age': 25,
    'gender': "Male",
    'region': "North",
    'policy_type': "Auto",
    'annual_premium': 4000,
    'claims_last_year': 1,
    'satisfaction_score': 4,
    'contract_length': 24,
    'customer_since': "2020-01-15"
}

prediction_results = predict_and_recommend(new_customer)
print("\nPrediction Results for New Customer:")
for key, value in prediction_results.items():
    print(f"- {key.replace('_', ' ').title()}: {value}")

